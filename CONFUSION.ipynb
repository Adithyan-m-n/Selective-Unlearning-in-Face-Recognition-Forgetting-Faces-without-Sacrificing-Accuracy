{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_metrics(confusion_matrix):\n",
    "    # Calculate accuracy\n",
    "    accuracy = np.trace(confusion_matrix) / np.sum(confusion_matrix)\n",
    "\n",
    "    # Calculate precision, recall, and F1-score for each class\n",
    "    precision = np.zeros(confusion_matrix.shape[0])\n",
    "    recall = np.zeros(confusion_matrix.shape[0])\n",
    "    f1_score = np.zeros(confusion_matrix.shape[0])\n",
    "\n",
    "    for i in range(confusion_matrix.shape[0]):\n",
    "        true_positive = confusion_matrix[i, i]\n",
    "        false_positive = np.sum(confusion_matrix[:, i]) - true_positive\n",
    "        false_negative = np.sum(confusion_matrix[i, :]) - true_positive\n",
    "\n",
    "        # Precision\n",
    "        precision[i] = true_positive / (true_positive + false_positive) if (true_positive + false_positive) != 0 else 0\n",
    "\n",
    "        # Recall\n",
    "        recall[i] = true_positive / (true_positive + false_negative) if (true_positive + false_negative) != 0 else 0\n",
    "\n",
    "        # F1-score\n",
    "        f1_score[i] = 2 * (precision[i] * recall[i]) / (precision[i] + recall[i]) if (precision[i] + recall[i]) != 0 else 0\n",
    "\n",
    "    # Take the average precision, recall, and F1-score across all classes\n",
    "    avg_precision = np.mean(precision)\n",
    "    avg_recall = np.mean(recall)\n",
    "    avg_f1_score = np.mean(f1_score)\n",
    "\n",
    "    return accuracy, avg_precision, avg_recall, avg_f1_score\n",
    "\n",
    "\n",
    "# Given confusion matrix\n",
    "confusion_matrix = np.array([\n",
    "    [7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [3, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [2, 0, 9, 0, 4, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 13, 1, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 14, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 5, 9, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 2, 4, 0, 5, 0, 0, 0, 3],\n",
    "    [4, 0, 0, 0, 0, 0, 0, 9, 0, 1, 1],\n",
    "    [0, 0, 0, 0, 5, 0, 0, 0, 10, 0, 0],\n",
    "    [2, 0, 0, 0, 0, 0, 0, 0, 0, 12, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 14]\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy, avg_precision, avg_recall, avg_f1_score = calculate_metrics(confusion_matrix)\n",
    "\n",
    "# Print the results\n",
    "print(\"After 40 epoch of model training:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", avg_precision)\n",
    "print(\"Recall:\", avg_recall)\n",
    "print(\"F1 Score:\", avg_f1_score)\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "# Given confusion matrix\n",
    "confusion_matrix = np.array([\n",
    "    [6, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "    [0, 13, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 15, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 1, 13, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 1, 13, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 1, 2, 0, 1, 0, 9, 2],\n",
    "    [0, 0, 1, 1, 1, 0, 11, 0, 0, 0, 0],\n",
    "    [0, 0, 1, 0, 0, 0, 0, 14, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 15, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 14, 0],\n",
    "    [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 14]\n",
    "])\n",
    "\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy, avg_precision, avg_recall, avg_f1_score = calculate_metrics(confusion_matrix)\n",
    "\n",
    "# Print the results\n",
    "print(\"After 10 epoch of unlearning (re training) by novel method\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", avg_precision)\n",
    "print(\"Recall:\", avg_recall)\n",
    "print(\"F1 Score:\", avg_f1_score)\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "# Given confusion matrix\n",
    "confusion_matrix = np.array([\n",
    "    [7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [1, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 15, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 14, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 14, 0, 0, 0, 0, 0, 0],\n",
    "    [14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 14, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 15, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 15, 0, 0],\n",
    "    [1, 0, 0, 0, 0, 0, 1, 0, 0, 12, 0],\n",
    "    [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 14]\n",
    "])\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy, avg_precision, avg_recall, avg_f1_score = calculate_metrics(confusion_matrix)\n",
    "\n",
    "# Print the results\n",
    "print(\"After 10 epoch of unlearning (re training) by comparison method:\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", avg_precision)\n",
    "print(\"Recall:\", avg_recall)\n",
    "print(\"F1 Score:\", avg_f1_score)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
